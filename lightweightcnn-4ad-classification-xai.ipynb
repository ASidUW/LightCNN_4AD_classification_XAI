{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1892744,"sourceType":"datasetVersion","datasetId":1127745},{"sourceId":2999523,"sourceType":"datasetVersion","datasetId":1837631},{"sourceId":5962731,"sourceType":"datasetVersion","datasetId":3419493}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Standard library\nimport os\nfrom random import randint\n\n# Third‑party: core\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm\n\n# Third‑party: scikit‑learn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import (\n    confusion_matrix,\n    classification_report,\n    matthews_corrcoef as MCC,\n    balanced_accuracy_score as BAS,\n)\n\n# Third‑party: TensorFlow / Keras (use tf.keras consistently)\nimport tensorflow as tf\nfrom tensorflow.keras import Model, Sequential\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.layers import (\n    Input, Conv2D, SeparableConv2D, MaxPooling2D, Flatten,\n    Dense, Dropout, BatchNormalization, GlobalAveragePooling2D,\n    Concatenate,\n)\nfrom tensorflow.keras.callbacks import (\n    EarlyStopping, ModelCheckpoint, ReduceLROnPlateau,\n)\nfrom tensorflow.keras.optimizers import Adam, RMSprop\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay\nfrom tensorflow.keras.regularizers import l1, l2\n\n# Reproducibility\nprint(\"TensorFlow Version:\", tf.__version__)\ntf.random.set_seed(42)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T20:53:26.873464Z","iopub.execute_input":"2025-08-23T20:53:26.874376Z","iopub.status.idle":"2025-08-23T20:53:26.918628Z","shell.execute_reply.started":"2025-08-23T20:53:26.874346Z","shell.execute_reply":"2025-08-23T20:53:26.917513Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"import os\nimport pandas as pd\nfrom tqdm import tqdm\n\nimages = []\nlabels = []\n# Specify the 'train' subfolder path\ntrain_subfolder_path = os.path.join('/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset', 'train')\n\n# Loop through each subfolder in the 'train' directory\nfor folder in tqdm(os.listdir(train_subfolder_path)):\n    subfolder_path = os.path.join(train_subfolder_path, folder)\n    # Loop through each image file in the subfolder\n    for image_filename in os.listdir(subfolder_path): \n        image_path = os.path.join(subfolder_path, image_filename)\n        images.append(image_path)\n        labels.append(folder)  # The label is the name of the subfolder\n\ndf = pd.DataFrame({'image': images, 'label': labels})\nprint(df)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-30T14:51:40.193507Z","iopub.execute_input":"2024-05-30T14:51:40.194308Z","iopub.status.idle":"2024-05-30T14:51:41.503104Z","shell.execute_reply.started":"2024-05-30T14:51:40.194244Z","shell.execute_reply":"2024-05-30T14:51:41.502215Z"}}},{"cell_type":"markdown","source":"print(df.groupby(['label']).count())","metadata":{"execution":{"iopub.status.busy":"2024-05-30T14:52:01.878842Z","iopub.execute_input":"2024-05-30T14:52:01.879662Z","iopub.status.idle":"2024-05-30T14:52:01.893392Z","shell.execute_reply.started":"2024-05-30T14:52:01.879629Z","shell.execute_reply":"2024-05-30T14:52:01.892434Z"}}},{"cell_type":"markdown","source":"plt.figure(figsize=(15,8))\nax = sns.countplot(x=df.label,palette='Set1')\nax.set_xlabel(\"Class\",fontsize=20)\nax.set_ylabel(\"Count\",fontsize=20)\nplt.title('The Number Of Samples For Each Class',fontsize=20)\nplt.grid(True)\nplt.xticks(rotation=45)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-28T10:31:42.441876Z","iopub.execute_input":"2024-05-28T10:31:42.442274Z","iopub.status.idle":"2024-05-28T10:31:42.848434Z","shell.execute_reply.started":"2024-05-28T10:31:42.442243Z","shell.execute_reply":"2024-05-28T10:31:42.847175Z"}}},{"cell_type":"code","source":"class_names = [\"Mild Dementia\", \"Moderate Dementia\", \"Non Demented\", \"Very mild Dementia\"]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T13:09:43.848235Z","iopub.execute_input":"2024-12-14T13:09:43.849248Z","iopub.status.idle":"2024-12-14T13:09:43.853252Z","shell.execute_reply.started":"2024-12-14T13:09:43.849208Z","shell.execute_reply":"2024-12-14T13:09:43.852337Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class_names = [\"MD\", \"MoD\", \"ND\",\"VMildD\"]\n# [\"Mild AD\", \"Moderate AD\", \"Non AD\", \"Very Mild AD\"]\nprint(class_names)","metadata":{"execution":{"iopub.status.busy":"2024-12-14T10:32:22.895752Z","iopub.execute_input":"2024-12-14T10:32:22.896047Z","iopub.status.idle":"2024-12-14T10:32:22.901080Z","shell.execute_reply.started":"2024-12-14T10:32:22.896024Z","shell.execute_reply":"2024-12-14T10:32:22.900073Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Processing Kaggle dataset of 4 AD classes containing 6400 images**","metadata":{}},{"cell_type":"markdown","source":"import os\nfolder_path = '/kaggle/working/output/'\n# Create the new folder\nos.mkdir(folder_path)","metadata":{"execution":{"iopub.status.busy":"2024-05-28T11:43:39.906055Z","iopub.execute_input":"2024-05-28T11:43:39.906919Z","iopub.status.idle":"2024-05-28T11:43:39.911437Z","shell.execute_reply.started":"2024-05-28T11:43:39.906887Z","shell.execute_reply":"2024-05-28T11:43:39.910329Z"}}},{"cell_type":"markdown","source":"#output_dir = pathlib.Path('/kaggle/input/dataset-alzheimer/Alzheimer_s Dataset/train')\noutput_dir = pathlib.Path('/kaggle/input/alzheimer-mri-4-classes-dataset/Alzheimer_MRI_4_classes_dataset')\n#output_dir = pathlib.Path('/kaggle/input/alzheimer-mri-ds/Alzheimer_MRI_ds/Train')\nimage_count_train = len(list(output_dir.glob('*/*.jpg')))\nprint(image_count_train)","metadata":{"execution":{"iopub.status.busy":"2024-10-12T18:07:16.467077Z","iopub.execute_input":"2024-10-12T18:07:16.468039Z","iopub.status.idle":"2024-10-12T18:07:16.507816Z","shell.execute_reply.started":"2024-10-12T18:07:16.467995Z","shell.execute_reply":"2024-10-12T18:07:16.506490Z"}}},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T14:46:45.484901Z","iopub.execute_input":"2025-08-23T14:46:45.485168Z","iopub.status.idle":"2025-08-23T14:46:45.488845Z","shell.execute_reply.started":"2025-08-23T14:46:45.485147Z","shell.execute_reply":"2025-08-23T14:46:45.488186Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"import shutil\ndirectory_path = \"/kaggle/working/sample_dataset\"\n\nif os.path.exists(directory_path):\n    shutil.rmtree(directory_path)\nelse:\n    print(f\"The directory {directory_path} does not exist.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-12-14T10:36:15.861387Z","iopub.execute_input":"2024-12-14T10:36:15.861740Z","iopub.status.idle":"2024-12-14T10:36:15.935245Z","shell.execute_reply.started":"2024-12-14T10:36:15.861711Z","shell.execute_reply":"2024-12-14T10:36:15.934395Z"}}},{"cell_type":"markdown","source":"# Define the directories for saving the split data\ntrain_dir = 'train'\ntest_dir = 'test'\nclass_names = ['MildDemented', 'ModerateDemented', 'NonDemented', 'VeryMildDemented']\n\n# Create the class-labeled folders in both train and test directories\nfor class_name in class_names:\n    os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)\n    os.makedirs(os.path.join(test_dir, class_name), exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-13T18:39:41.022562Z","iopub.execute_input":"2024-10-13T18:39:41.022982Z","iopub.status.idle":"2024-10-13T18:39:41.029649Z","shell.execute_reply.started":"2024-10-13T18:39:41.022927Z","shell.execute_reply":"2024-10-13T18:39:41.028725Z"}}},{"cell_type":"markdown","source":"# Function to save images into respective class folders\ndef save_images(data, labels, folder_dir):\n    for i, image in enumerate(data):\n        label_idx = np.argmax(labels[i])  # Get the class index\n        class_name = class_names[label_idx]\n        image_path = os.path.join(folder_dir, class_name, f'image_{i}.png')\n        # Convert image back to [0,255] and save\n        image = (image * 255).astype(np.uint8)\n        tf.keras.preprocessing.image.save_img(image_path, image)\n\n# Save training images\nsave_images(X_train_data, y_train_labels, train_dir)\n\n# Save testing images\nsave_images(X_test, y_test, test_dir)\n\nprint(f\"Training images saved to {train_dir}\")\nprint(f\"Testing images saved to {test_dir}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-13T18:45:09.237908Z","iopub.execute_input":"2024-10-13T18:45:09.238245Z","iopub.status.idle":"2024-10-13T18:45:30.864842Z","shell.execute_reply.started":"2024-10-13T18:45:09.238211Z","shell.execute_reply":"2024-10-13T18:45:30.863875Z"}}},{"cell_type":"markdown","source":"**resizing the saved images**","metadata":{}},{"cell_type":"code","source":"output_dir_train='/kaggle/working/train'\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nSize=(128, 128)#(176, 208)#(200,200)#(176,176)#(224, 224)\nwork_dr = ImageDataGenerator(\n    rescale = 1./255\n)\ntrain_data_gen = work_dr.flow_from_directory(output_dir_train,target_size=Size, batch_size=5120, shuffle=True)\n\nfor i in range(len(train_data_gen)):\n    X_train_data, y_train_labels = train_data_gen[i]\nprint(X_train_data.shape, y_train_labels.shape) ","metadata":{"execution":{"iopub.status.busy":"2025-08-23T20:55:21.069417Z","iopub.execute_input":"2025-08-23T20:55:21.069907Z","iopub.status.idle":"2025-08-23T20:55:27.697018Z","shell.execute_reply.started":"2025-08-23T20:55:21.069885Z","shell.execute_reply":"2025-08-23T20:55:27.696267Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"output_dir_test='/kaggle/working/test'\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n#Size=(150, 150)\nSize=(128, 128)#(176, 208)#(200,200)#(176,176)#(224, 224)\nwork_dr = ImageDataGenerator(\n    rescale = 1./255\n)\ntest_data_gen = work_dr.flow_from_directory(output_dir_test,target_size=Size, batch_size=1280,shuffle=True)\n\nfor i in range(len(test_data_gen)):\n    X_test, y_test = test_data_gen[i]\nprint( X_test.shape, y_test.shape) ","metadata":{"execution":{"iopub.status.busy":"2025-08-23T21:55:09.707769Z","iopub.execute_input":"2025-08-23T21:55:09.708520Z","iopub.status.idle":"2025-08-23T21:55:10.843977Z","shell.execute_reply.started":"2025-08-23T21:55:09.708493Z","shell.execute_reply":"2025-08-23T21:55:10.843214Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define a function to display images\ndef display_loaded_images(images, labels, class_indices, num_images=9):\n    label_names = {v: k for k, v in class_indices.items()}  # Map label indices to class names\n    plt.figure(figsize=(10, 10))\n    \n    for i in range(num_images):\n        plt.subplot(3, 3, i + 1)  # Create a 3x3 grid\n        plt.imshow(images[i])  # Display the image\n        label_idx = np.argmax(labels[i])  # Get the label index\n        plt.title(label_names[label_idx])  # Display the class name as the title\n        plt.axis('off')  # Hide the axes for a cleaner look\n\n    plt.show()\n\n# Display the first 9 images and their labels\nprint(\"Displaying training images:\")\ndisplay_loaded_images(X_train_data, y_train_labels, train_data_gen.class_indices)","metadata":{"execution":{"iopub.status.busy":"2025-08-23T20:57:46.168557Z","iopub.execute_input":"2025-08-23T20:57:46.168843Z","iopub.status.idle":"2025-08-23T20:57:46.785240Z","shell.execute_reply.started":"2025-08-23T20:57:46.168822Z","shell.execute_reply":"2025-08-23T20:57:46.784530Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Proposed Dual branch 5 CNN layered model architecture**","metadata":{}},{"cell_type":"code","source":"    image_width=128 \n    image_height=128 \n    \n    input_shape=(image_width, image_height, 3)\n    inputs = Input(shape=input_shape)\n    conv1 = Conv2D(16, (3,3), activation='relu', kernel_regularizer=l2(0.02))(inputs)\n    bn1_1a = BatchNormalization()(conv1)\n    conv1a = Conv2D(32, (3,3), activation='relu',kernel_regularizer=l2(0.02))(bn1_1a)\n    bn1_1 = BatchNormalization()(conv1a)\n    pool1_1 = MaxPooling2D()(bn1_1)\n    conv2a = Conv2D(32, (3, 3), activation='relu', kernel_regularizer=l2(0.02))(pool1_1)\n    bn1_2 = BatchNormalization()(conv2a)\n    pool1_2 = MaxPooling2D()(bn1_2)\n    conv3 = Conv2D(32, (3, 3), activation='relu', kernel_regularizer=l2(0.02))(pool1_2)\n    bn1_3 = BatchNormalization()(conv3)\n    pool1_3 = MaxPooling2D()(bn1_3)\n    conv4 = Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.02))(pool1_3)\n    bn1_4 = BatchNormalization()(conv4)\n    pool1_4 = MaxPooling2D()(bn1_4)\n    x1 = Flatten()(pool1_4)\n    x1 = Dense(64, activation='relu')(x1)\n \n    conv2_1 = Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.02))(inputs)\n    bn2_1a = BatchNormalization()(conv2_1)\n    conv2_1a = Conv2D(32, (3, 3), activation='relu', kernel_regularizer=l2(0.02))(bn2_1a)\n    bn2_1 = BatchNormalization()(conv2_1a)\n    pool2_1 = MaxPooling2D()(bn2_1)\n \n    conv2_2a =  Conv2D(32, (3, 3), activation='relu', kernel_regularizer=l2(0.02))(pool2_1)\n    bn2_2 = BatchNormalization()(conv2_2a)\n    pool2_2 = MaxPooling2D()(bn2_2)\n     \n    conv2_3 =  Conv2D(32, (3, 3), activation='relu', kernel_regularizer=l2(0.02))(bn2_2)\n    bn2_3 = BatchNormalization()(conv2_3)\n    pool2_3 = MaxPooling2D()(bn2_3)\n    \n    conv2_4 =  Conv2D(16, (3, 3), activation='relu', kernel_regularizer=l2(0.02))(pool2_3)\n    bn2_4 = BatchNormalization()(conv2_4)\n    pool2_4 = MaxPooling2D()(bn2_4)\n\n    x2 = Flatten()(pool2_4)\n    x2 = Dense(64, activation='relu')(x2)\n    \n    x = Concatenate()([x1,x2])\n    x = Dropout(0.2)(x)\n    x = Dense(512, activation='relu')(x)\n    output = Dense(4, activation='softmax')(x)  # 4 classes for classification\n    custom_model = Model(inputs=inputs, outputs=output, name=\"CNNs_AD4_5cnnL\")\n\n    METRICS = [\n        tf.keras.metrics.CategoricalAccuracy(name='acc'),\n        tf.keras.metrics.Precision(name='precision'),\n        tf.keras.metrics.Recall(name='recall'),\n        tf.keras.metrics.AUC(name='auc'),\n        tf.keras.metrics.F1Score(name='f1_score')]\n\n\n   \n\n    custom_model.compile(optimizer=Adam(learning_rate=0.0005),\n                              loss=tf.losses.CategoricalCrossentropy(),\n                              metrics=METRICS)\n\n    custom_model.summary()\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T21:01:01.647673Z","iopub.execute_input":"2025-08-23T21:01:01.648561Z","iopub.status.idle":"2025-08-23T21:01:02.364841Z","shell.execute_reply.started":"2025-08-23T21:01:01.648531Z","shell.execute_reply":"2025-08-23T21:01:02.364316Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"    checkpointest = tf.keras.callbacks.ModelCheckpoint(\n    filepath='/kaggle/working/final_AD4_CNNs_5L.keras',\n    save_weights_only=False,\n    monitor='val_acc',  # Monitor the categorical accuracy for multiclass classification\n    save_best_only=True,\n    save_freq=\"epoch\"\n    )\n\n    # Define custom callback to stop training when accuracy exceeds 99%\n    class MyCallback(tf.keras.callbacks.Callback):\n        def on_epoch_end(self, epoch, logs={}):\n            if logs.get('acc') > 0.999:  # Use 'categorical_accuracy' for accuracy metric\n                print(\"\\nReached accuracy threshold! Terminating training.\")\n                self.model.stop_training = True\n\n    # Instantiate custom callback\n    my_callbacktest = MyCallback()\n\n    # Define EarlyStopping callback\n    early_stopping = tf.keras.callbacks.EarlyStopping(\n        monitor='val_loss',\n        patience=10,\n        restore_best_weights=True\n    )\nhistory = custom_model.fit(X_train_data, y_train_labels, \n                                validation_split=0.2, \n                                epochs=30, batch_size=32, \n                                callbacks=[checkpointest, my_callbacktest, early_stopping], \n                                shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-11-04T11:52:32.128103Z","iopub.execute_input":"2024-11-04T11:52:32.128884Z","iopub.status.idle":"2024-11-04T11:52:32.135968Z","shell.execute_reply.started":"2024-11-04T11:52:32.128843Z","shell.execute_reply":"2024-11-04T11:52:32.134864Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**K-fold cross validation**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import StratifiedKFold\nimport numpy as np\n\ncheckpointest = tf.keras.callbacks.ModelCheckpoint(filepath='/kaggle/working/final_AD4_CNNs_5cnnL_10f.keras',\n    save_weights_only=False,\n    monitor='val_acc',  # Monitor the categorical accuracy for multiclass classification\n    save_best_only=True,\n    save_freq=\"epoch\"\n    )\n\n    # Define custom callback to stop training when accuracy exceeds 99%\nclass MyCallback(tf.keras.callbacks.Callback):\n        def on_epoch_end(self, epoch, logs={}):\n            if logs.get('acc') > 0.999:  # Use 'categorical_accuracy' for accuracy metric\n                print(\"\\nReached accuracy threshold! Terminating training.\")\n                self.model.stop_training = True\n\n    # Instantiate custom callback\nmy_callbacktest = MyCallback()\n\n    # Define EarlyStopping callback\nearly_stopping = tf.keras.callbacks.EarlyStopping(\n        monitor='val_loss',\n        patience=15,\n        restore_best_weights=True\n    )\n#histor\n\n    # Define learning rate scheduler callback\ndef lr_scheduler(epoch, lr, epochs=60):\n        initial = 1e-3\n        if epoch <= epochs * 0.1:\n            return initial * 1.0\n        elif epoch > epochs * 0.1 and epoch < epochs * 0.25:\n            new_lr = lr * tf.math.exp(-0.1).numpy()\n            print(\"Learning rate after exponential decay:\", new_lr)\n            return new_lr\n        else:\n            new_lr = lr * tf.math.exp(-0.008).numpy()\n            print(\"Learning rate after exp_decay:\", new_lr)\n            return new_lr\n\nlr_scheduling = tf.keras.callbacks.LearningRateScheduler(lr_scheduler)\n    \n# Initialize StratifiedKFold # keep n_splits=5 for 5 fold and n_splits=8 for 8-fold\nskf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n\n# Lists to store results\nX_train_list, X_val_list, y_train_list, y_val_list = [], [], [], []\nhistory_list = []\nfold = 0 \n\n# Perform StratifiedKFold split and store train/validation data\nfor train_index, val_index in skf.split(X_train_data, np.argmax(y_train_labels, axis=1)):\n    X_train_fold, X_val_fold = X_train_data[train_index], X_train_data[val_index]\n    y_train_fold, y_val_fold = y_train_labels[train_index], y_train_labels[val_index]\n    \n    X_train_list.append(X_train_fold)\n    X_val_list.append(X_val_fold)\n    y_train_list.append(y_train_fold)\n    y_val_list.append(y_val_fold)\n\n# Print shapes of the datasets\nfor i in range(len(X_train_list)):\n    print('Fold', i+1)\n    print('X_train shape:', X_train_list[i].shape)\n    print('y_train shape:', y_train_list[i].shape)\n    print('X_val shape:', X_val_list[i].shape)\n    print('y_val shape:', y_val_list[i].shape)\n    \n    # Train the model\n    history = custom_model.fit(X_train_fold, y_train_fold, \n                                validation_data=(X_val_fold, y_val_fold), \n                                epochs=30, batch_size=32, \n                                callbacks=[checkpointest, my_callbacktest, early_stopping], \n                                shuffle=True)\n    \n    # Save training history for this fold\n    history_list.append(history.history)\n    import pickle\n    # Save the training histories for all folds\n    with open('/kaggle/working/CNNs_training_AD4_10f_final.pkl', 'wb') as file:\n        pickle.dump(history_list, file)\n    # Save the trained model\n    custom_model.save('/kaggle/working/final_CNNs_AD4_model_10fold{}.keras'.format(fold))\n    \n    fold += 1\n    \nimport pickle\n# Save the training histories for all folds\nwith open('/kaggle/working/CNNs_training_AD4_10f_final.pkl', 'wb') as file:\n    pickle.dump(history_list, file)","metadata":{"execution":{"iopub.status.busy":"2024-11-04T19:42:04.026164Z","iopub.execute_input":"2024-11-04T19:42:04.027104Z","iopub.status.idle":"2024-11-04T20:18:06.012195Z","shell.execute_reply.started":"2024-11-04T19:42:04.027059Z","shell.execute_reply":"2024-11-04T20:18:06.011121Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pickle\nwith open('/kaggle/working/CNNs_training_AD4_10f_final.pkl', 'rb') as file:\n\n    history_list = pickle.load(file)","metadata":{"execution":{"iopub.status.busy":"2025-08-23T21:11:46.058141Z","iopub.execute_input":"2025-08-23T21:11:46.058427Z","iopub.status.idle":"2025-08-23T21:11:46.152895Z","shell.execute_reply.started":"2025-08-23T21:11:46.058410Z","shell.execute_reply":"2025-08-23T21:11:46.152309Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Iterate over each fold's training history\nfor i, history in enumerate(history_list):\n    plt.figure(figsize=(10, 5))\n    \n    # Plot training & validation accuracy values\n    plt.subplot(1, 2, 1)\n    plt.plot(history['acc'],'bo--',linewidth=2)\n    plt.plot(history['val_acc'],'ro--',linewidth=2)\n    plt.title('Model accuracy - Fold {}'.format(i+1))\n    plt.ylabel('Accuracy')\n    plt.xlabel('Epoch')\n    plt.xticks(range(0,len(history['acc'])+1,2), range(0, len(history['acc'])+1,2))  # Set x-axis ticks with interval of 5 epochs\n    plt.ylim(0, 1)  # Set y-axis limits from 0 to 1\n    plt.legend(['Train', 'Validation'], loc='upper left')\n    \n    # Plot training & validation loss values\n    plt.subplot(1, 2, 2)\n    plt.plot(history['loss'],'bo--',linewidth=2)\n    plt.plot(history['val_loss'],'ro--',linewidth=2)\n    plt.title('Model loss - Fold {}'.format(i+1))\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.xticks(range(0,len(history['loss'])+1,2), range(0, len(history['loss'])+1,2) ) # Force integer ticks\n    #plt.ylim(0, 1)  # Set y-axis limits from 0 to 1\n    plt.legend(['Train', 'Validation'], loc='upper left')\n    \n    plt.tight_layout()\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T21:11:47.554599Z","iopub.execute_input":"2025-08-23T21:11:47.555478Z","iopub.status.idle":"2025-08-23T21:11:51.405104Z","shell.execute_reply.started":"2025-08-23T21:11:47.555441Z","shell.execute_reply":"2025-08-23T21:11:51.404305Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**8-fold training history**","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport pickle\nwith open('/kaggle/working/CNNs_training_AD4_8f_final.pkl', 'rb') as file:\n\n    history_list = pickle.load(file)\n# Iterate over each fold's training history\nfor i, history in enumerate(history_list):\n    plt.figure(figsize=(10, 5))\n    \n    # Plot training & validation accuracy values\n    plt.subplot(1, 2, 1)\n    plt.plot(history['acc'],'bo--',linewidth=2)\n    plt.plot(history['val_acc'],'ro--',linewidth=2)\n    plt.title('Model accuracy - Fold {}'.format(i+1))\n    plt.ylabel('Accuracy')\n    plt.xlabel('Epoch')\n    plt.xticks(range(0,len(history['acc'])+1,2), range(0, len(history['acc'])+1,2))  # Set x-axis ticks with interval of 5 epochs\n    plt.ylim(0, 1)  # Set y-axis limits from 0 to 1\n    plt.legend(['Train', 'Validation'], loc='upper left')\n    \n    # Plot training & validation loss values\n    plt.subplot(1, 2, 2)\n    plt.plot(history['loss'],'bo--',linewidth=2)\n    plt.plot(history['val_loss'],'ro--',linewidth=2)\n    plt.title('Model loss - Fold {}'.format(i+1))\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.xticks(range(0,len(history['loss'])+1,2), range(0, len(history['loss'])+1,2) ) # Force integer ticks\n    #plt.ylim(0, 1)  # Set y-axis limits from 0 to 1\n    plt.legend(['Train', 'Validation'], loc='upper left')\n    \n    plt.tight_layout()\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T21:12:27.505249Z","iopub.execute_input":"2025-08-23T21:12:27.505598Z","iopub.status.idle":"2025-08-23T21:12:30.140929Z","shell.execute_reply.started":"2025-08-23T21:12:27.505574Z","shell.execute_reply":"2025-08-23T21:12:30.140258Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model8f=tf.keras.models.load_model(\"/kaggle/working/final_AD4_CNNs_5cnnL_8f.keras\")\ntest_scores = model8f.evaluate(X_test, y_test)\nprint(\"Testing Accuracy: %.4f%%\" % (test_scores[1] * 100))\n#Print the classification report of the tested data\npred_labels = model8f.predict(X_test)\n#Since the labels are softmax arrays, we need to roundoff to have it in the form of 0s and 1s,\n#similar to the test_labels\ndef roundoff(arr):\n    \"\"\"To round off according to the argmax of each predicted label array. \"\"\"\n    arr[np.argwhere(arr != arr.max())] = 0\n    arr[np.argwhere(arr == arr.max())] = 1\n    return arr\n\nfor labels in pred_labels:\n    labels = roundoff(labels)\n\n# Classification report\n#print(classification_report(np.argmax(y_test, axis=1), np.argmax(pred_labels, axis=1)))\nprint(classification_report(y_test, pred_labels, target_names=class_names))\n\n\n# Plot the confusion matrix to understand the classification in detailsnio\npred_ls = np.argmax(pred_labels, axis=1)\ntest_ls = np.argmax(y_test, axis=1)\n\nconf_arr = confusion_matrix(test_ls, pred_ls)\n\nplt.figure(figsize=(16, 12), dpi=200, facecolor='w', edgecolor='k')\n\n#ax = sns.heatmap(conf_arr, cmap='Greens', annot=True, fmt='d', xticklabels=class_names,yticklabels=class_names, annot_kws={\"fontsize\": 24})\n #Plot heatmap\nax = sns.heatmap(conf_arr, cmap='Blues', annot=True, fmt='d')\n# Increase font size for annotations\nfor text in ax.texts:\n    text.set_fontsize(36)  # Adjust the font size as needed\n\n# Increase font size for x-axis and y-axis labels\n#plt.xticks(np.arange(len(class_names)), class_names, fontsize=14)\n#plt.yticks(np.arange(len(class_names)), class_names, fontsize=14)\n\nax.set_xticklabels(class_names, rotation=0, ha='center', fontsize=24)\nax.set_yticklabels(class_names, rotation=0, va='center', fontsize=24)\n\n#plt.title(\"AD classification, Batch Size=32, 8fold\", fontsize=16)  # Title font size\nplt.xlabel(\"Prediction\", fontsize=18)  # X label font size\nplt.ylabel(\"Actual\", fontsize=18)  # Y label font size\nplt.show(ax)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T21:14:10.816730Z","iopub.execute_input":"2025-08-23T21:14:10.817521Z","iopub.status.idle":"2025-08-23T21:14:20.141097Z","shell.execute_reply.started":"2025-08-23T21:14:10.817494Z","shell.execute_reply":"2025-08-23T21:14:20.140381Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import classification_report, confusion_matrix\nclass_names=[\"MD\", \"MoD\", \"ND\", \"VMD\"]\n# 1) Predict and convert to class ids\npred_probs = model8f.predict(X_test, verbose=0)\ny_true = np.argmax(y_test, axis=1) if y_test.ndim == 2 else y_test\ny_pred = np.argmax(pred_probs, axis=1)\n\n# 2) Classification report as a DataFrame\nreport_dict = classification_report(\n    y_true,\n    y_pred,\n    target_names=class_names,\n    output_dict=True,\n    digits=4\n)\nreport_df = pd.DataFrame(report_dict).T\n\n# Keep per-class rows + macro/weighted averages; drop 'support' from heatmap\nrows = list(class_names) + ['weighted avg']\nreport_heat = report_df.loc[rows, ['precision', 'recall', 'f1-score']]\n\n# (optional) show class supports in the y-axis labels\nsupports = np.bincount(y_true, minlength=len(class_names))\nrow_labels = [f'{c} (n={s})' for c, s in zip(class_names, supports)] + ['Average']\nreport_heat.index = row_labels\n\n# 3) Plot the classification report heatmap\nplt.figure(figsize=(8, 0.6*len(report_heat)+2), dpi=200)\nax = sns.heatmap(\n    report_heat, annot=True, fmt=\".4f\", cmap=\"coolwarm\", cbar=True, linewidths=0.5, annot_kws={\"size\": 20} )\n#ax = sns.heatmap(report_heat, annot=True, fmt='.3f', cmap='Greens', vmin=0, vmax=1, cbar=True)\nax.set_title('Classification Report (heatmap)')\nax.set_xlabel('Metric')\nax.set_ylabel('Class')\nax.set_yticklabels(ax.get_yticklabels(), rotation=0, va='center')\nplt.tight_layout()\nplt.show()\n\n# 4) (optional) Confusion matrix heatmap (you already have this)\ncm = confusion_matrix(y_true, y_pred)\nplt.figure(figsize=(8, 6), dpi=200)\nax = sns.heatmap(conf_arr, cmap='Blues', annot=True, fmt='d')\n# Increase font size for annotations\nfor text in ax.texts:\n    text.set_fontsize(24)  # Adjust the font size as needed\n\n# Increase font size for x-axis and y-axis labels\n#plt.xticks(np.arange(len(class_names)), class_names, fontsize=14)\n#plt.yticks(np.arange(len(class_names)), class_names, fontsize=14)\n\nax.set_xticklabels(class_names, rotation=0, ha='center', fontsize=20)\nax.set_yticklabels(class_names, rotation=0, va='center', fontsize=20)\n\n#plt.title(\"AD classification, Batch Size=32, 8fold\", fontsize=16)  # Title font size\nplt.xlabel(\"Prediction\", fontsize=14)  # X label font size\nplt.ylabel(\"Actual\", fontsize=14)  # Y label font size\nplt.show(ax)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T21:22:39.172301Z","iopub.execute_input":"2025-08-23T21:22:39.172678Z","iopub.status.idle":"2025-08-23T21:22:41.038004Z","shell.execute_reply.started":"2025-08-23T21:22:39.172653Z","shell.execute_reply":"2025-08-23T21:22:41.037241Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#5-fold\nmodel5f=tf.keras.models.load_model('/kaggle/working/final_AD4_CNNs_5cnnL.keras')\ntest_scores = model5f.evaluate(X_test, y_test)\nprint(\"Testing Accuracy: %.4f%%\" % (test_scores[1] * 100))\n\n#Print the classification report of the tested data\npred_labels = model5f.predict(X_test)\n#Since the labels are softmax arrays, we need to roundoff to have it in the form of 0s and 1s,\n#similar to the test_labels\ndef roundoff(arr):\n    \"\"\"To round off according to the argmax of each predicted label array. \"\"\"\n    arr[np.argwhere(arr != arr.max())] = 0\n    arr[np.argwhere(arr == arr.max())] = 1\n    return arr\n\nfor labels in pred_labels:\n    labels = roundoff(labels)\n\n# Classification report\n#print(classification_report(np.argmax(y_test, axis=1), np.argmax(pred_labels, axis=1)))\nprint(classification_report(y_test, pred_labels, target_names=class_names))\n\n\n# Plot the confusion matrix to understand the classification in detailsnio\npred_ls = np.argmax(pred_labels, axis=1)\ntest_ls = np.argmax(y_test, axis=1)\n\nconf_arr = confusion_matrix(test_ls, pred_ls)\n\nplt.figure(figsize=(16, 12), dpi=200, facecolor='w', edgecolor='k')\n\n#ax = sns.heatmap(conf_arr, cmap='Greens', annot=True, fmt='d', xticklabels=class_names,yticklabels=class_names, annot_kws={\"fontsize\": 24})\n #Plot heatmap\nax = sns.heatmap(conf_arr, cmap='Blues', annot=True, fmt='d')\n# Increase font size for annotations\nfor text in ax.texts:\n    text.set_fontsize(36)  # Adjust the font size as needed\n\n# Increase font size for x-axis and y-axis labels\n#plt.xticks(np.arange(len(class_names)), class_names, fontsize=14)\n#plt.yticks(np.arange(len(class_names)), class_names, fontsize=14)\n\nax.set_xticklabels(class_names, rotation=0, ha='center', fontsize=24)\nax.set_yticklabels(class_names, rotation=0, va='center', fontsize=24)\n\n#plt.title(\"AD classification, Batch Size=32, 5fold\", fontsize=16)  # Title font size\nplt.xlabel(\"Prediction\", fontsize=18)  # X label font size\nplt.ylabel(\"Actual\", fontsize=18)  # Y label font size\nplt.show(ax)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T21:24:24.406001Z","iopub.execute_input":"2025-08-23T21:24:24.406728Z","iopub.status.idle":"2025-08-23T21:24:32.121965Z","shell.execute_reply.started":"2025-08-23T21:24:24.406700Z","shell.execute_reply":"2025-08-23T21:24:32.121058Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#10-fold\nmodel10f=tf.keras.models.load_model('/kaggle/working/final_AD4_CNNs_5cnnL_10f.keras')\ntest_scores = model10f.evaluate(X_test, y_test)\nprint(\"Testing Accuracy: %.4f%%\" % (test_scores[1] * 100))\n\n#Print the classification report of the tested data\npred_labels = model10f.predict(X_test)\n#Since the labels are softmax arrays, we need to roundoff to have it in the form of 0s and 1s,\n#similar to the test_labels\ndef roundoff(arr):\n    \"\"\"To round off according to the argmax of each predicted label array. \"\"\"\n    arr[np.argwhere(arr != arr.max())] = 0\n    arr[np.argwhere(arr == arr.max())] = 1\n    return arr\n\nfor labels in pred_labels:\n    labels = roundoff(labels)\n\n# Classification report\n#print(classification_report(np.argmax(y_test, axis=1), np.argmax(pred_labels, axis=1)))\nprint(classification_report(y_test, pred_labels, target_names=class_names))\n\n\n# Plot the confusion matrix to understand the classification in detailsnio\npred_ls = np.argmax(pred_labels, axis=1)\ntest_ls = np.argmax(y_test, axis=1)\n\nconf_arr = confusion_matrix(test_ls, pred_ls)\n\nplt.figure(figsize=(16, 12), dpi=200, facecolor='w', edgecolor='k')\n\n#ax = sns.heatmap(conf_arr, cmap='Greens', annot=True, fmt='d', xticklabels=class_names,yticklabels=class_names, annot_kws={\"fontsize\": 24})\n #Plot heatmap\nax = sns.heatmap(conf_arr, cmap='Blues', annot=True, fmt='d')\n# Increase font size for annotations\nfor text in ax.texts:\n    text.set_fontsize(36)  # Adjust the font size as needed\n\n# Increase font size for x-axis and y-axis labels\n#plt.xticks(np.arange(len(class_names)), class_names, fontsize=14)\n#plt.yticks(np.arange(len(class_names)), class_names, fontsize=14)\n\nax.set_xticklabels(class_names, rotation=0, ha='center', fontsize=24)\nax.set_yticklabels(class_names, rotation=0, va='center', fontsize=24)\n\n#plt.title(\"AD classification, Batch Size=32, 5fold\", fontsize=16)  # Title font size\nplt.xlabel(\"Prediction\", fontsize=18)  # X label font size\nplt.ylabel(\"Actual\", fontsize=18)  # Y label font size\nplt.show(ax)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T21:24:55.654547Z","iopub.execute_input":"2025-08-23T21:24:55.654859Z","iopub.status.idle":"2025-08-23T21:25:04.022486Z","shell.execute_reply.started":"2025-08-23T21:24:55.654835Z","shell.execute_reply":"2025-08-23T21:25:04.021637Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"    from keras.optimizers import RMSprop\n    from tensorflow.keras.regularizers import l1_l2\n\n    image_width=128 \n    image_height=128 \n    input_shape=(image_width, image_height, 3)\n \n    inputs = Input(shape=input_shape)\n    conv1 = Conv2D(16, (3,3), activation='relu', kernel_regularizer=l2(0.02))(inputs)\n    bn1_1a = BatchNormalization()(conv1)\n    \n    conv1a = Conv2D(32, (3,3), activation='relu',kernel_regularizer=l2(0.02))(bn1_1a)\n    bn1_1 = BatchNormalization()(conv1a)\n    #pool1_1 = MaxPooling2D()(bn1_1)\n    \n    conv2a = Conv2D(32, (3, 3), activation='relu', kernel_regularizer=l2(0.02))(pool1_1)\n    bn1_2 = BatchNormalization()(conv2a)\n    pool1_2 = MaxPooling2D()(bn1_2)\n    conv3 = Conv2D(32, (3, 3), activation='relu', kernel_regularizer=l2(0.02))(pool1_2)\n    bn1_3 = BatchNormalization()(conv3)\n    pool1_3 = MaxPooling2D()(bn1_3)\n \n    conv4 = Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.02))(pool1_3)\n    bn1_4 = BatchNormalization()(conv4)\n    pool1_4 = MaxPooling2D()(bn1_4)\n\n    x1 = Flatten()(pool1_4)\n    x1 = Dense(64, activation='relu')(x1)\n \n    conv2_1 = Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.02))(inputs)\n    bn2_1a = BatchNormalization()(conv2_1)\n    conv2_1a = Conv2D(32, (3, 3), activation='relu', kernel_regularizer=l2(0.02))(bn2_1a)\n    bn2_1 = BatchNormalization()(conv2_1a)\n    pool2_1 = MaxPooling2D()(bn2_1)\n \n    conv2_2a =  Conv2D(32, (3, 3), activation='relu', kernel_regularizer=l2(0.02))(pool2_1)\n    bn2_2 = BatchNormalization()(conv2_2a)\n    pool2_2 = MaxPooling2D()(bn2_2)\n     \n    conv2_3 =  Conv2D(32, (3, 3), activation='relu', kernel_regularizer=l2(0.02))(pool2_2)\n    bn2_3 = BatchNormalization()(conv2_3)\n    pool2_3 = MaxPooling2D()(bn2_3)\n    \n    conv2_4 =  Conv2D(16, (3, 3), activation='relu', kernel_regularizer=l2(0.02))(pool2_3)\n    bn2_4 = BatchNormalization()(conv2_4)\n    pool2_4 = MaxPooling2D()(bn2_4)\n\n    x2 = Flatten()(pool2_4)\n    x2 = Dense(64, activation='relu')(x2)\n    \n    x = Concatenate()([x1,x2])\n\n    x = Dropout(0.4)(x)\n    x = Dense(512, activation='relu')(x)\n \n\n    output = Dense(4, activation='softmax')(x)  # Assuming 5 classes for classification\n\n    METRICS = [\n        tf.keras.metrics.CategoricalAccuracy(name='acc'),\n        tf.keras.metrics.Precision(name='precision'),\n        tf.keras.metrics.Recall(name='recall'),\n        tf.keras.metrics.AUC(name='auc'),\n        tf.keras.metrics.F1Score(name='f1_score')]\n\n\n    custom_model2 = Model(inputs=inputs, outputs=output, name=\"CNNs_AD4_128_3cnnL\")\n\n    custom_model2.compile(optimizer=Adam(learning_rate=0.0005),\n                              loss=tf.losses.CategoricalCrossentropy(),\n                              metrics=METRICS)\n\n    custom_model2.summary()\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2025-08-23T21:02:41.827362Z","iopub.execute_input":"2025-08-23T21:02:41.828036Z","iopub.status.idle":"2025-08-23T21:02:42.064147Z","shell.execute_reply.started":"2025-08-23T21:02:41.828000Z","shell.execute_reply":"2025-08-23T21:02:42.063584Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#model with 3 CNN layers\n# Evaluating the model on the data\n#test_scores = custom_model2.evaluate(X_test, y_test)\n#print(\"Testing Accuracy: %.4f%%\" % (test_scores[1] * 100))\nmodel=tf.keras.models.load_model('/kaggle/working/test_AD4_CNNs_3L.keras')\ntest_scores = model.evaluate(X_test, y_test)\nprint(\"Testing Accuracy: %.4f%%\" % (test_scores[1] * 100))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T21:04:16.679869Z","iopub.execute_input":"2025-08-23T21:04:16.680222Z","iopub.status.idle":"2025-08-23T21:04:24.239096Z","shell.execute_reply.started":"2025-08-23T21:04:16.680185Z","shell.execute_reply":"2025-08-23T21:04:24.238251Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluating the model on the data\n#test_scores = custom_model2.evaluate(X_test, y_test)\n#print(\"Testing Accuracy: %.4f%%\" % (test_scores[1] * 100))\n#model with 4 CNN layers\nmodel=tf.keras.models.load_model('/kaggle/working/test_AD4_CNNs_4L.keras')\ntest_scores = model.evaluate(X_test, y_test)\nprint(\"Testing Accuracy: %.4f%%\" % (test_scores[1] * 100))","metadata":{"execution":{"iopub.status.busy":"2025-08-23T21:04:52.738002Z","iopub.execute_input":"2025-08-23T21:04:52.738686Z","iopub.status.idle":"2025-08-23T21:04:58.612896Z","shell.execute_reply.started":"2025-08-23T21:04:52.738659Z","shell.execute_reply":"2025-08-23T21:04:58.612078Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_test=test_data\ny_test=test_labels","metadata":{"execution":{"iopub.status.busy":"2024-10-05T10:43:46.440977Z","iopub.status.idle":"2024-10-05T10:43:46.441465Z","shell.execute_reply.started":"2024-10-05T10:43:46.441212Z","shell.execute_reply":"2024-10-05T10:43:46.441236Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **OASIS**","metadata":{}},{"cell_type":"code","source":"import os, random\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\n\n# --- 1) Full determinism ---\nSEED = 42\nos.environ[\"PYTHONHASHSEED\"] = str(SEED)\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)\ntry:\n    tf.config.experimental.enable_op_determinism(True)\nexcept Exception:\n    pass\n\n# --- 2) Load data ONCE in a fixed order (no shuffle) ---\noutput_dir = '/kaggle/working/sample_dataset' # saved the images in the working directory from input\nSize = (64, 64)\n\ndatagen = ImageDataGenerator(rescale=1./255)\ngen = datagen.flow_from_directory(\n    output_dir,\n    target_size=Size,\n    batch_size=99999,          # large to fetch all in one batch\n    shuffle=False,              # <- critical for reproducibility\n    class_mode='categorical'    # one-hot labels to match your model\n)\n\nX_all, Y_all = next(gen)        # X_all: (N,H,W,C), Y_all: (N,4) one-hot\ny_ids = np.argmax(Y_all, axis=1)  # class ids for stratification only\nN = X_all.shape[0]\nidx = np.arange(N)\n\n# --- 3) Deterministic stratified split BY INDICES ---\nidx_train, idx_test = train_test_split(\n    idx,\n    test_size=0.2,\n    random_state=SEED,\n    shuffle=True,\n    stratify=y_ids\n)\n\nX_train_data = X_all[idx_train]\nX_test        = X_all[idx_test]\ny_train_labels = Y_all[idx_train]   # KEEP one-hot for your categorical loss\ny_test         = Y_all[idx_test]    # KEEP one-hot for evaluation\n\nprint('X_train', X_train_data.shape)\nprint('X_test',  X_test.shape)\nprint('y_train', y_train_labels.shape)\nprint('y_test',  y_test.shape)\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T21:51:16.485768Z","iopub.execute_input":"2025-08-23T21:51:16.486133Z","iopub.status.idle":"2025-08-23T21:51:57.612703Z","shell.execute_reply.started":"2025-08-23T21:51:16.486109Z","shell.execute_reply":"2025-08-23T21:51:57.611886Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import StratifiedKFold\nimport numpy as np\n\ncheckpointest = tf.keras.callbacks.ModelCheckpoint(filepath='/kaggle/working/model64_AD4_OAsis_5cnnl.keras',\n    save_weights_only=False,\n    monitor='val_acc',  # Monitor the categorical accuracy for multiclass classification\n    save_best_only=True,\n    save_freq=\"epoch\"\n    )\n\n    # Define custom callback to stop training when accuracy exceeds 99%\nclass MyCallback(tf.keras.callbacks.Callback):\n        def on_epoch_end(self, epoch, logs={}):\n            if logs.get('acc') > 0.999:  # Use 'categorical_accuracy' for accuracy metric\n                print(\"\\nReached accuracy threshold! Terminating training.\")\n                self.model.stop_training = True\n\n    # Instantiate custom callback\nmy_callbacktest = MyCallback()\n\n    # Define EarlyStopping callback\nearly_stopping = tf.keras.callbacks.EarlyStopping(\n        monitor='val_loss',\n        patience=15,\n        restore_best_weights=True\n    )\n#histor\n\n    # Define learning rate scheduler callback\ndef lr_scheduler(epoch, lr, epochs=60):\n        initial = 1e-3\n        if epoch <= epochs * 0.1:\n            return initial * 1.0\n        elif epoch > epochs * 0.1 and epoch < epochs * 0.25:\n            new_lr = lr * tf.math.exp(-0.1).numpy()\n            print(\"Learning rate after exponential decay:\", new_lr)\n            return new_lr\n        else:\n            new_lr = lr * tf.math.exp(-0.008).numpy()\n            print(\"Learning rate after exp_decay:\", new_lr)\n            return new_lr\n\nlr_scheduling = tf.keras.callbacks.LearningRateScheduler(lr_scheduler)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T18:42:22.254287Z","iopub.execute_input":"2025-08-23T18:42:22.254578Z","iopub.status.idle":"2025-08-23T18:42:22.261409Z","shell.execute_reply.started":"2025-08-23T18:42:22.254549Z","shell.execute_reply":"2025-08-23T18:42:22.260553Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"    from keras.optimizers import RMSprop\n    from tensorflow.keras.regularizers import l1_l2\n    from tensorflow.keras import Sequential, Input\n    from tensorflow.keras.layers import Dense, Dropout\n    from tensorflow.keras.layers import Conv2D, Flatten\n    import pathlib\n    import tensorflow as tf\n    import matplotlib.pyplot as plt\n    import numpy as np\n    import pandas as pd\n    import os\n    import PIL\n    from tensorflow import keras\n    from tensorflow.keras import layers\n    from tensorflow.keras.models import Sequential\n    from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n    from tensorflow.keras.optimizers import Adam # - Works\n    import random\n    from glob import glob\n    import seaborn as sns\n    from tensorflow.keras.losses import SparseCategoricalCrossentropy\n    import matplotlib.pyplot as plt\n    import matplotlib.image as img\n    import warnings\n    warnings.filterwarnings('ignore')\n    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n    tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n    image_width=64#128 \n    image_height=64#128 \n    input_shape=(image_width, image_height, 3)\n \n    inputs = Input(shape=input_shape)\n    conv1 = Conv2D(16, (3,3), activation='relu', kernel_regularizer=l2(0.02))(inputs)\n    bn1_1a = BatchNormalization()(conv1)\n    conv1a = Conv2D(32, (3,3), activation='relu',kernel_regularizer=l2(0.02))(bn1_1a)\n    bn1_1 = BatchNormalization()(conv1a)\n    pool1_1 = MaxPooling2D()(bn1_1)\n    conv2a = Conv2D(32, (3, 3), activation='relu', kernel_regularizer=l2(0.02))(pool1_1)\n    bn1_2 = BatchNormalization()(conv2a)\n    pool1_2 = MaxPooling2D()(bn1_2)\n    conv3 = Conv2D(32, (3, 3), activation='relu', kernel_regularizer=l2(0.02))(pool1_2)\n    bn1_3 = BatchNormalization()(conv3)\n    pool1_3 = MaxPooling2D()(bn1_3)\n    conv4 = Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.02))(pool1_3)\n    bn1_4 = BatchNormalization()(conv4)\n    pool1_4 = MaxPooling2D()(bn1_4)\n    x1 = Flatten()(pool1_4)\n    x1 = Dense(64, activation='relu')(x1)\n \n    conv2_1 = Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.02))(inputs)\n    bn2_1a = BatchNormalization()(conv2_1)\n    conv2_1a = Conv2D(32, (3, 3), activation='relu', kernel_regularizer=l2(0.02))(bn2_1a)\n    bn2_1 = BatchNormalization()(conv2_1a)\n    pool2_1 = MaxPooling2D()(bn2_1)\n \n    conv2_2a =  Conv2D(32, (3, 3), activation='relu', kernel_regularizer=l2(0.02))(pool2_1)\n    bn2_2 = BatchNormalization()(conv2_2a)\n    pool2_2 = MaxPooling2D()(bn2_2)\n     \n    conv2_3 =  Conv2D(32, (3, 3), activation='relu', kernel_regularizer=l2(0.02))(bn2_2)\n    bn2_3 = BatchNormalization()(conv2_3)\n    pool2_3 = MaxPooling2D()(bn2_3)\n    \n    conv2_4 =  Conv2D(16, (3, 3), activation='relu', kernel_regularizer=l2(0.02))(pool2_3)\n    bn2_4 = BatchNormalization()(conv2_4)\n    pool2_4 = MaxPooling2D()(bn2_4)\n\n    x2 = Flatten()(pool2_4)\n    x2 = Dense(64, activation='relu')(x2)\n    \n    x = Concatenate()([x1,x2])\n    x = Dropout(0.2)(x)\n    x = Dense(512, activation='relu')(x)\n    \n\n    output = Dense(4, activation='softmax')(x)  # Assuming 5 classes for classification\n\n    METRICS = [\n        tf.keras.metrics.CategoricalAccuracy(name='acc'),\n        tf.keras.metrics.Precision(name='precision'),\n        tf.keras.metrics.Recall(name='recall'),\n        tf.keras.metrics.AUC(name='auc'),\n        tf.keras.metrics.F1Score(name='f1_score')]\n\n\n    model64 = Model(inputs=inputs, outputs=output, name=\"CNNs_AD4_64_5cnnL_Oasis\")\n\n    model64.compile(optimizer=Adam(learning_rate=0.0005),\n                              loss=tf.losses.CategoricalCrossentropy(),\n                              metrics=METRICS)\n\n    model64.summary()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T19:03:51.871878Z","iopub.execute_input":"2025-08-23T19:03:51.872145Z","iopub.status.idle":"2025-08-23T19:03:52.149843Z","shell.execute_reply.started":"2025-08-23T19:03:51.872128Z","shell.execute_reply":"2025-08-23T19:03:52.149239Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history = model64.fit(X_train_data, y_train_labels, validation_split=0.1, epochs=30,batch_size=32,\n                               callbacks=[checkpointest, my_callbacktest, early_stopping], \n                                shuffle=True)# early_stopping,lr_scheduling, \nimport pickle\n\n    # Assuming 'history' is the variable containing the training history\nwith open('/kaggle/working/train_oasis_cnn5l.pkl', 'wb') as file:\n        pickle.dump(history.history, file)","metadata":{"execution":{"iopub.status.busy":"2025-08-23T18:42:24.913999Z","iopub.execute_input":"2025-08-23T18:42:24.914515Z","iopub.status.idle":"2025-08-23T18:59:28.579957Z","shell.execute_reply.started":"2025-08-23T18:42:24.914493Z","shell.execute_reply":"2025-08-23T18:59:28.579254Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plotting the trend of the metrics during training\nimport matplotlib.pyplot as plt\nfig, ax = plt.subplots(1, 3, figsize=(30, 6))\nax = ax.ravel()\n\nfor i, metric in enumerate([\"acc\", \"auc\", \"loss\"]):\n    ax[i].plot(history.history[metric],'bo--',linewidth=2)\n    ax[i].plot(history.history[\"val_\" + metric], \"ro--\",linewidth=2)\n    ax[i].set_title(\"Model {}\".format(metric))\n    ax[i].set_xlabel(\"Epochs\")\n    ax[i].set_ylabel(metric)\n    ax[i].legend([\"Training\", \"Validation\"])\n\n#plt.ylim(0, 1)  # Set y-axis limits from 0 to 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T19:04:33.233163Z","iopub.execute_input":"2025-08-23T19:04:33.233567Z","iopub.status.idle":"2025-08-23T19:04:33.861037Z","shell.execute_reply.started":"2025-08-23T19:04:33.233542Z","shell.execute_reply":"2025-08-23T19:04:33.860374Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model64=tf.keras.models.load_model(\"/kaggle/working/model64_AD4_OAsis_5cnnl.keras\")\ntest_scores = model64.evaluate(X_test, y_test)\nprint(\"Testing Accuracy: %.2f%%\" % (test_scores[1] * 100))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T21:52:40.697501Z","iopub.execute_input":"2025-08-23T21:52:40.697792Z","iopub.status.idle":"2025-08-23T21:52:51.538397Z","shell.execute_reply.started":"2025-08-23T21:52:40.697762Z","shell.execute_reply":"2025-08-23T21:52:51.537701Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model64=tf.keras.models.load_model(\"/kaggle/working/model64_AD4_OAsis.keras\")\ntest_scores = model64.evaluate(X_test, y_test)\nprint(\"Testing Accuracy: %.2f%%\" % (test_scores[1] * 100))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T21:52:11.796140Z","iopub.execute_input":"2025-08-23T21:52:11.796956Z","iopub.status.idle":"2025-08-23T21:52:22.177829Z","shell.execute_reply.started":"2025-08-23T21:52:11.796926Z","shell.execute_reply":"2025-08-23T21:52:22.177153Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_scores = model64.evaluate(X_test, y_test)\nprint(\"Testing Accuracy: %.2f%%\" % (test_scores[1] * 100))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T13:07:38.575665Z","iopub.execute_input":"2024-12-14T13:07:38.576026Z","iopub.status.idle":"2024-12-14T13:07:46.272263Z","shell.execute_reply.started":"2024-12-14T13:07:38.575993Z","shell.execute_reply":"2024-12-14T13:07:46.271432Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Print the classification report of the tested data\npred_labels = model64.predict(X_test)\n#Since the labels are softmax arrays, we need to roundoff to have it in the form of 0s and 1s,\n#similar to the test_labels\ndef roundoff(arr):\n    \"\"\"To round off according to the argmax of each predicted label array. \"\"\"\n    arr[np.argwhere(arr != arr.max())] = 0\n    arr[np.argwhere(arr == arr.max())] = 1\n    return arr\n\nfor labels in pred_labels:\n    labels = roundoff(labels)\n\n# Classification report\n#print(classification_report(np.argmax(y_test, axis=1), np.argmax(pred_labels, axis=1)))\nprint(classification_report(y_test, pred_labels, target_names=class_names, digits=4))\n\n\n# Plot the confusion matrix to understand the classification in detailsnio\npred_ls = np.argmax(pred_labels, axis=1)\ntest_ls = np.argmax(y_test, axis=1)\n\nconf_arr = confusion_matrix(test_ls, pred_ls)\n\nplt.figure(figsize=(16, 12), dpi=200, facecolor='w', edgecolor='k')\n\n#ax = sns.heatmap(conf_arr, cmap='Greens', annot=True, fmt='d', xticklabels=class_names,yticklabels=class_names, annot_kws={\"fontsize\": 24})\n #Plot heatmap\nax = sns.heatmap(conf_arr, cmap='Greens', annot=True, fmt='d')\n# Increase font size for annotations\nfor text in ax.texts:\n    text.set_fontsize(36)  # Adjust the font size as needed\n\n# Increase font size for x-axis and y-axis labels\n#plt.xticks(np.arange(len(class_names)), class_names, fontsize=14)\n#plt.yticks(np.arange(len(class_names)), class_names, fontsize=14)\n\nax.set_xticklabels(class_names, rotation=45, ha='right', fontsize=24)\nax.set_yticklabels(class_names, rotation=0, va='center', fontsize=24)\n\nplt.title(\" 64x64 image size\", fontsize=16)  # Title font size\nplt.xlabel(\"Prediction\", fontsize=18)  # X label font size\nplt.ylabel(\"Truth\", fontsize=18)  # Y label font size\nplt.show(ax)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T21:52:57.202481Z","iopub.execute_input":"2025-08-23T21:52:57.203102Z","iopub.status.idle":"2025-08-23T21:53:04.574613Z","shell.execute_reply.started":"2025-08-23T21:52:57.203074Z","shell.execute_reply":"2025-08-23T21:53:04.573956Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import classification_report, confusion_matrix\nclass_names=[\"MD\", \"MoD\", \"ND\", \"VMD\"]\n# 1) Predict and convert to class ids\npred_probs = model64.predict(X_test, verbose=0)\ny_true = np.argmax(y_test, axis=1) if y_test.ndim == 2 else y_test\ny_pred = np.argmax(pred_probs, axis=1)\n\n# 2) Classification report as a DataFrame\nreport_dict = classification_report(\n    y_true,\n    y_pred,\n    target_names=class_names,\n    output_dict=True,\n    digits=4\n)\nreport_df = pd.DataFrame(report_dict).T\n\n# Keep per-class rows + macro/weighted averages; drop 'support' from heatmap\nrows = list(class_names) + ['weighted avg']\nreport_heat = report_df.loc[rows, ['precision', 'recall', 'f1-score']]\n\n# (optional) show class supports in the y-axis labels\nsupports = np.bincount(y_true, minlength=len(class_names))\nrow_labels = [f'{c} (n={s})' for c, s in zip(class_names, supports)] + ['Average']\nreport_heat.index = row_labels\n\n# 3) Plot the classification report heatmap\nplt.figure(figsize=(8, 0.6*len(report_heat)+2), dpi=200)\nax = sns.heatmap(\n    report_heat, annot=True, fmt=\".4f\", cmap=\"coolwarm\", cbar=True, linewidths=0.5, annot_kws={\"size\": 20} )\n#ax = sns.heatmap(report_heat, annot=True, fmt='.3f', cmap='Greens', vmin=0, vmax=1, cbar=True)\nax.set_title('Classification Report (heatmap)')\nax.set_xlabel('Metric')\nax.set_ylabel('Class')\nax.set_yticklabels(ax.get_yticklabels(), rotation=0, va='center')\nplt.tight_layout()\nplt.show()\n\n# 4) (optional) Confusion matrix heatmap (you already have this)\ncm = confusion_matrix(y_true, y_pred)\nplt.figure(figsize=(8, 6), dpi=200)\nax = sns.heatmap(cm, annot=True, fmt='d', cmap='Greens',\n                 xticklabels=class_names, yticklabels=class_names)\nax.set_title('Confusion Matrix')\nax.set_xlabel('Predicted')\nax.set_ylabel('Actual')\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T21:53:20.302668Z","iopub.execute_input":"2025-08-23T21:53:20.303286Z","iopub.status.idle":"2025-08-23T21:53:25.699469Z","shell.execute_reply.started":"2025-08-23T21:53:20.303257Z","shell.execute_reply":"2025-08-23T21:53:25.698677Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Print the classification report of the tested data\npred_labels = model64.predict(X_test)\n#Since the labels are softmax arrays, we need to roundoff to have it in the form of 0s and 1s,\n#similar to the test_labels\ndef roundoff(arr):\n    \"\"\"To round off according to the argmax of each predicted label array. \"\"\"\n    arr[np.argwhere(arr != arr.max())] = 0\n    arr[np.argwhere(arr == arr.max())] = 1\n    return arr\n\nfor labels in pred_labels:\n    labels = roundoff(labels)\n\n# Classification report\n#print(classification_report(np.argmax(y_test, axis=1), np.argmax(pred_labels, axis=1)))\nprint(classification_report(y_test, pred_labels, target_names=class_names, digits=4))\n\n\n# Plot the confusion matrix to understand the classification in detailsnio\npred_ls = np.argmax(pred_labels, axis=1)\ntest_ls = np.argmax(y_test, axis=1)\n\nconf_arr = confusion_matrix(test_ls, pred_ls)\n\nplt.figure(figsize=(16, 12), dpi=200, facecolor='w', edgecolor='k')\n\n#ax = sns.heatmap(conf_arr, cmap='Greens', annot=True, fmt='d', xticklabels=class_names,yticklabels=class_names, annot_kws={\"fontsize\": 24})\n #Plot heatmap\nax = sns.heatmap(conf_arr, cmap='Greens', annot=True, fmt='d')\n# Increase font size for annotations\nfor text in ax.texts:\n    text.set_fontsize(36)  # Adjust the font size as needed\n\n# Increase font size for x-axis and y-axis labels\n#plt.xticks(np.arange(len(class_names)), class_names, fontsize=14)\n#plt.yticks(np.arange(len(class_names)), class_names, fontsize=14)\n\nax.set_xticklabels(class_names, rotation=45, ha='right', fontsize=24)\nax.set_yticklabels(class_names, rotation=0, va='center', fontsize=24)\n\nplt.title(\" 64x64 image size\", fontsize=16)  # Title font size\nplt.xlabel(\"Prediction\", fontsize=18)  # X label font size\nplt.ylabel(\"Actual\", fontsize=18)  # Y label font size\nplt.show(ax)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T19:49:42.692580Z","iopub.execute_input":"2025-08-23T19:49:42.693526Z","iopub.status.idle":"2025-08-23T19:49:48.209912Z","shell.execute_reply.started":"2025-08-23T19:49:42.693496Z","shell.execute_reply":"2025-08-23T19:49:48.209251Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Visualization of features via LIME**","metadata":{}},{"cell_type":"code","source":"n=1\nmodel8f=tf.keras.models.load_model(\"/kaggle/working/final_AD4_CNNs_5cnnL_8f.keras\")\npredictions = model8f.predict(X_test[n:n+1])\nprint(\"true label: \",{np.argmax(y_test[n:n+1])})\nprint(\"predicted label: \",{np.argmax(predictions)})","metadata":{"execution":{"iopub.status.busy":"2025-08-23T21:55:29.061955Z","iopub.execute_input":"2025-08-23T21:55:29.062252Z","iopub.status.idle":"2025-08-23T21:55:30.503871Z","shell.execute_reply.started":"2025-08-23T21:55:29.062234Z","shell.execute_reply":"2025-08-23T21:55:30.503132Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predictions","metadata":{"execution":{"iopub.status.busy":"2025-08-23T21:35:02.942375Z","iopub.execute_input":"2025-08-23T21:35:02.943030Z","iopub.status.idle":"2025-08-23T21:35:02.948601Z","shell.execute_reply.started":"2025-08-23T21:35:02.943000Z","shell.execute_reply":"2025-08-23T21:35:02.947902Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get the shape of the original image\noriginal_shape = X_test[n:n+1].shape\n\n# Calculate the total number of pixels in the image\ntotal_pixels = original_shape[1] * original_shape[2] * original_shape[3]\n\n# Assuming the image has 3 color channels (RGB)\nchannels = 3\n\n# Reshape the flattened data to 2D color image format\nX_test_reshaped = X_test[n:n+1].reshape((1, original_shape[1], original_shape[2], channels))\n\n# Print the shape of the reshaped array\nprint(\"Reshaped array shape:\", X_test_reshaped.shape)\n\nimport cv2\n\n# Convert RGB image to grayscale\ngray_image = cv2.cvtColor(X_test_reshaped[0], cv2.COLOR_RGB2GRAY)\n\n# Expand dimensions to make it 3D (2D image with a single channel)\ngray_image_3d = gray_image[:, :, np.newaxis]\n\n# Print the shape of the grayscale image\nprint(\"Grayscale image shape:\", gray_image_3d.shape)\nimport matplotlib.pyplot as plt\n\n# Display the grayscale image\nplt.imshow(gray_image_3d[:, :, 0], cmap='gray')\nplt.axis('off')  # Turn off axis\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2025-08-23T21:35:08.550724Z","iopub.execute_input":"2025-08-23T21:35:08.551511Z","iopub.status.idle":"2025-08-23T21:35:08.678407Z","shell.execute_reply.started":"2025-08-23T21:35:08.551483Z","shell.execute_reply":"2025-08-23T21:35:08.677667Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from lime.lime_image import LimeImageExplainer \nexplainer = LimeImageExplainer() \nexplanation = explainer.explain_instance(gray_image_3d[:, :, 0], model8f.predict, top_labels=2, num_samples=100, random_seed=42) \nexplanation","metadata":{"execution":{"iopub.status.busy":"2025-08-23T21:35:14.397141Z","iopub.execute_input":"2025-08-23T21:35:14.397803Z","iopub.status.idle":"2025-08-23T21:35:17.365882Z","shell.execute_reply.started":"2025-08-23T21:35:14.397776Z","shell.execute_reply":"2025-08-23T21:35:17.364984Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"n=506\npredictions = model8f.predict(X_test[n:n+1])\npredicted_class_index = np.argmax(predictions)\n\n# Assuming you have a list of class labels\n#class_labels = ['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4']\n\n#nf=6 # number of features\n# Get the label corresponding to the predicted class index\npredicted_label = class_names[predicted_class_index]\nprint(\"true label: \",{np.argmax(y_test[n:n+1])})\nprint(\"predicted label_claaa: \",{np.argmax(predictions)})\nprint(\"predicted_label:\",predicted_label )\nclass_names\npredicted_class_index\n","metadata":{"execution":{"iopub.status.busy":"2025-08-23T21:35:24.640331Z","iopub.execute_input":"2025-08-23T21:35:24.641290Z","iopub.status.idle":"2025-08-23T21:35:24.726117Z","shell.execute_reply.started":"2025-08-23T21:35:24.641261Z","shell.execute_reply":"2025-08-23T21:35:24.725543Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom lime.lime_image import LimeImageExplainer \nfrom skimage.segmentation import mark_boundaries\n\n# Assuming X_test_reshaped, gray_image_3d, and explanation are already defined as per your code\n# Get the shape of the original image\noriginal_shape = X_test[n:n+1].shape\n\n# Calculate the total number of pixels in the image\ntotal_pixels = original_shape[1] * original_shape[2] * original_shape[3]\n\n# Assuming the image has 3 color channels (RGB)\nchannels = 3\n\n# Reshape the flattened data to 2D color image format\nX_test_reshaped = X_test[n:n+1].reshape((1, original_shape[1], original_shape[2], channels))\n\n# Print the shape of the reshaped array\nprint(\"Reshaped array shape:\", X_test_reshaped.shape)\n\nimport cv2\n\n# Convert RGB image to grayscale\ngray_image = cv2.cvtColor(X_test_reshaped[0], cv2.COLOR_RGB2GRAY)\n\n# Expand dimensions to make it 3D (2D image with a single channel)\ngray_image_3d = gray_image[:, :, np.newaxis]\n\n############LIME EXPLANER\n\nexplainer = LimeImageExplainer() \nexplanation = explainer.explain_instance(gray_image_3d[:, :, 0], model8f.predict, top_labels=4, num_samples=1050, random_seed=42) \nexplanation\n\n\n# Display images in a row\nfig, axes = plt.subplots(1, 4, figsize=(20, 5))  # Create a row of 4 images\n\n# First image: grayscale image\naxes[0].imshow(gray_image_3d[:, :, 0], cmap='gray')\naxes[0].set_title('Original Image')\naxes[0].axis('off')  # Turn off axis\n\nnf=2\n\n# Second image: image with mask (positive only, num_features=2)\ntemp, mask = explanation.get_image_and_mask(predicted_class_index, positive_only=True, num_features=nf, hide_rest=True)\naxes[1].imshow(mark_boundaries(temp, mask))\naxes[1].set_title('Top Positive features')\naxes[1].axis('off')  # Turn off axis\n\n# Third image: image with mask (positive only, num_features=2, hide_rest=False)\ntemp, mask = explanation.get_image_and_mask(predicted_class_index, positive_only=True, num_features=nf, hide_rest=False)\naxes[2].imshow(mark_boundaries(temp, mask))\naxes[2].set_title('Top Positive features (Full Image)')\naxes[2].axis('off')  # Turn off axis\n\n# Fourth image: image with mask (positive + negative, num_features=6)\ntemp, mask = explanation.get_image_and_mask(predicted_class_index, positive_only=False, num_features=nf, hide_rest=False)\naxes[3].imshow(mark_boundaries(temp, mask))\naxes[3].set_title('Top Positive & Negative Features')\naxes[3].axis('off')  # Turn off axis\n\n# Display the images\nplt.tight_layout()  # Adjust layout to avoid overlap\nplt.show()\n\nprint(\"true label: \",{np.argmax(y_test[n:n+1])})\n\npredicted_class_index = np.argmax(predictions)\n# Get the label corresponding to the predicted class index\npredicted_label = class_names[predicted_class_index]\nprint(\"predicted_label:\",predicted_label )\nprint(\"predicted_label:\",predicted_class_index)","metadata":{"execution":{"iopub.status.busy":"2025-08-23T21:37:54.653502Z","iopub.execute_input":"2025-08-23T21:37:54.653821Z","iopub.status.idle":"2025-08-23T21:38:04.314566Z","shell.execute_reply.started":"2025-08-23T21:37:54.653798Z","shell.execute_reply":"2025-08-23T21:38:04.313729Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom lime.lime_image import LimeImageExplainer \nfrom skimage.segmentation import mark_boundaries\n\nn=444\n# Get the shape of the original image\noriginal_shape = X_test[n:n+1].shape\n\n# Calculate the total number of pixels in the image\ntotal_pixels = original_shape[1] * original_shape[2] * original_shape[3]\n\n# Assuming the image has 3 color channels (RGB)\nchannels = 3\n\n# Reshape the flattened data to 2D color image format\nX_test_reshaped = X_test[n:n+1].reshape((1, original_shape[1], original_shape[2], channels))\n\n# Print the shape of the reshaped array\nprint(\"Reshaped array shape:\", X_test_reshaped.shape)\n\nimport cv2\n\n# Convert RGB image to grayscale\ngray_image = cv2.cvtColor(X_test_reshaped[0], cv2.COLOR_RGB2GRAY)\n\n# Expand dimensions to make it 3D (2D image with a single channel)\ngray_image_3d = gray_image[:, :, np.newaxis]\n\n############LIME EXPLANER\n\nexplainer = LimeImageExplainer() \nexplanation = explainer.explain_instance(gray_image_3d[:, :, 0], model8f.predict, top_labels=2, num_samples=500, random_seed=42) \nexplanation\n\n\n# Display images in a row\nfig, axes = plt.subplots(1, 4, figsize=(20, 5))  # Create a row of 4 images\n\n# First image: grayscale image\naxes[0].imshow(gray_image_3d[:, :, 0], cmap='gray')\naxes[0].set_title('Original Image')\naxes[0].axis('off')  # Turn off axis\n\nnf=2\n\n# Second image: image with mask (positive only, num_features=2)\ntemp, mask = explanation.get_image_and_mask(predicted_class_index, positive_only=True, num_features=nf, hide_rest=True)\naxes[1].imshow(mark_boundaries(temp, mask))\naxes[1].set_title('Top Positive features')\naxes[1].axis('off')  # Turn off axis\n\n# Third image: image with mask (positive only, num_features=2, hide_rest=False)\ntemp, mask = explanation.get_image_and_mask(predicted_class_index, positive_only=True, num_features=nf, hide_rest=False)\naxes[2].imshow(mark_boundaries(temp, mask))\naxes[2].set_title('Top Positive features (Full Image)')\naxes[2].axis('off')  # Turn off axis\n\n# Fourth image: image with mask (positive + negative, num_features=6)\ntemp, mask = explanation.get_image_and_mask(predicted_class_index, positive_only=False, num_features=nf, hide_rest=False)\naxes[3].imshow(mark_boundaries(temp, mask))\naxes[3].set_title('Top Positive & Negative Features')\naxes[3].axis('off')  # Turn off axis\n\n# Display the images\nplt.tight_layout()  # Adjust layout to avoid overlap\nplt.show()\n\nprint(\"true label: \",{np.argmax(y_test[n:n+1])})\n\npredicted_class_index = np.argmax(predictions)\n# Get the label corresponding to the predicted class index\npredicted_label = class_names[predicted_class_index]\nprint(\"predicted_label:\",predicted_label )\nprint(\"predicted_label:\",predicted_class_index)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T21:43:51.595761Z","iopub.execute_input":"2025-08-23T21:43:51.596100Z","iopub.status.idle":"2025-08-23T21:43:57.188039Z","shell.execute_reply.started":"2025-08-23T21:43:51.596077Z","shell.execute_reply":"2025-08-23T21:43:57.187073Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom lime.lime_image import LimeImageExplainer \nfrom skimage.segmentation import mark_boundaries\n\nn=300\n# Get the shape of the original image\noriginal_shape = X_test[n:n+1].shape\n\n# Calculate the total number of pixels in the image\ntotal_pixels = original_shape[1] * original_shape[2] * original_shape[3]\n\n# Assuming the image has 3 color channels (RGB)\nchannels = 3\n\n# Reshape the flattened data to 2D color image format\nX_test_reshaped = X_test[n:n+1].reshape((1, original_shape[1], original_shape[2], channels))\n\n# Print the shape of the reshaped array\nprint(\"Reshaped array shape:\", X_test_reshaped.shape)\n\nimport cv2\n\n# Convert RGB image to grayscale\ngray_image = cv2.cvtColor(X_test_reshaped[0], cv2.COLOR_RGB2GRAY)\n\n# Expand dimensions to make it 3D (2D image with a single channel)\ngray_image_3d = gray_image[:, :, np.newaxis]\n\n############LIME EXPLANER\n\nexplainer = LimeImageExplainer() \nexplanation = explainer.explain_instance(gray_image_3d[:, :, 0], model8f.predict, top_labels=2, num_samples=500, random_seed=42) \nexplanation\n\n\n# Display images in a row\nfig, axes = plt.subplots(1, 4, figsize=(20, 5))  # Create a row of 4 images\n\n# First image: grayscale image\naxes[0].imshow(gray_image_3d[:, :, 0], cmap='gray')\naxes[0].set_title('Original Image')\naxes[0].axis('off')  # Turn off axis\n\nnf=2\n\n# Second image: image with mask (positive only, num_features=2)\ntemp, mask = explanation.get_image_and_mask(predicted_class_index, positive_only=True, num_features=nf, hide_rest=True)\naxes[1].imshow(mark_boundaries(temp, mask))\naxes[1].set_title('Top Positive features')\naxes[1].axis('off')  # Turn off axis\n\n# Third image: image with mask (positive only, num_features=2, hide_rest=False)\ntemp, mask = explanation.get_image_and_mask(predicted_class_index, positive_only=True, num_features=nf, hide_rest=False)\naxes[2].imshow(mark_boundaries(temp, mask))\naxes[2].set_title('Top Positive features (Full Image)')\naxes[2].axis('off')  # Turn off axis\n\n# Fourth image: image with mask (positive + negative, num_features=6)\ntemp, mask = explanation.get_image_and_mask(predicted_class_index, positive_only=False, num_features=nf, hide_rest=False)\naxes[3].imshow(mark_boundaries(temp, mask))\naxes[3].set_title('Top Positive & Negative Features')\naxes[3].axis('off')  # Turn off axis\n\n# Display the images\nplt.tight_layout()  # Adjust layout to avoid overlap\nplt.show()\n\nprint(\"true label: \",{np.argmax(y_test[n:n+1])})\n\npredicted_class_index = np.argmax(predictions)\n# Get the label corresponding to the predicted class index\npredicted_label = class_names[predicted_class_index]\nprint(\"predicted_label:\",predicted_label )\nprint(\"predicted_label:\",predicted_class_index)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T21:49:24.177112Z","iopub.execute_input":"2025-08-23T21:49:24.177890Z","iopub.status.idle":"2025-08-23T21:49:29.630804Z","shell.execute_reply.started":"2025-08-23T21:49:24.177859Z","shell.execute_reply":"2025-08-23T21:49:29.629897Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"img = np.squeeze(gray_image_3d)\nexplanation = explainer.explain_instance(img, model8f.predict, top_labels=2, num_samples=100)","metadata":{"execution":{"iopub.status.busy":"2025-08-23T21:36:55.265367Z","iopub.execute_input":"2025-08-23T21:36:55.266232Z","iopub.status.idle":"2025-08-23T21:36:56.352237Z","shell.execute_reply.started":"2025-08-23T21:36:55.266178Z","shell.execute_reply":"2025-08-23T21:36:56.351673Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#predictions = model2.predict(X_test_reshaped )\n#explainer = lime_image.LimeImageExplainer()\ntemp, mask = explanation.get_image_and_mask(predicted_class_index, positive_only=True, num_features=2, hide_rest=True)\nimgExplained = mark_boundaries(temp, mask)\n# plot image and mask together\nplt.imshow(mark_boundaries(temp  , mask))","metadata":{"execution":{"iopub.status.busy":"2025-08-23T21:37:00.563054Z","iopub.execute_input":"2025-08-23T21:37:00.563870Z","iopub.status.idle":"2025-08-23T21:37:00.745136Z","shell.execute_reply.started":"2025-08-23T21:37:00.563842Z","shell.execute_reply":"2025-08-23T21:37:00.744516Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\n#predictions = model2.predict(X_test_reshaped )\n#explainer = lime_image.LimeImageExplainer()\ntemp, mask = explanation.get_image_and_mask(predicted_class_index, positive_only=True, num_features=2, hide_rest=False)\nimgExplained = mark_boundaries(temp, mask)\n# plot image and mask together\nplt.imshow(mark_boundaries(temp  , mask))\n","metadata":{"execution":{"iopub.status.busy":"2025-08-23T21:45:01.149120Z","iopub.execute_input":"2025-08-23T21:45:01.149443Z","iopub.status.idle":"2025-08-23T21:45:01.344762Z","shell.execute_reply.started":"2025-08-23T21:45:01.149422Z","shell.execute_reply":"2025-08-23T21:45:01.343997Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\ntemp, mask = explanation.get_image_and_mask(predicted_class_index, positive_only=False, num_features=4, hide_rest=False)\nplt.imshow(mark_boundaries(temp, mask))\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T21:45:39.728124Z","iopub.execute_input":"2025-08-23T21:45:39.728478Z","iopub.status.idle":"2025-08-23T21:45:39.922728Z","shell.execute_reply.started":"2025-08-23T21:45:39.728454Z","shell.execute_reply":"2025-08-23T21:45:39.922105Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\ntemp, mask = explanation.get_image_and_mask(predicted_class_index, positive_only=False, num_features=6, hide_rest=False)\nplt.imshow(mark_boundaries(temp, mask))\n\n","metadata":{"execution":{"iopub.status.busy":"2025-08-23T21:45:11.747659Z","iopub.execute_input":"2025-08-23T21:45:11.748019Z","iopub.status.idle":"2025-08-23T21:45:11.933372Z","shell.execute_reply.started":"2025-08-23T21:45:11.747996Z","shell.execute_reply":"2025-08-23T21:45:11.932639Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\n# Define the paths\ndataset_path = \"/kaggle/input/alzheimer-mri-4-classes-dataset/Alzheimer_MRI_4_classes_dataset\"  # Replace with your actual path\nclasses = [\"MildDemented\", \"ModerateDemented\", \"NonDemented\", \"VeryMildDemented\"]\nsample_size = 5  # Number of images to display per class\n\n# Set up the plot grid\nfig, axes = plt.subplots(len(classes), sample_size, figsize=(15, 10))\nfig.suptitle(\"Sample Images from Each Class\", fontsize=16)\n\n# Loop through each class and display sample images\nfor i, class_name in enumerate(classes):\n    class_path = os.path.join(dataset_path, class_name)\n    images = os.listdir(class_path)[:sample_size]  # Get a few sample images\n    \n    for j, image_name in enumerate(images):\n        img_path = os.path.join(class_path, image_name)\n        img = Image.open(img_path).convert(\"RGB\")  # Convert to RGB if grayscale\n        axes[i, j].imshow(img)\n        axes[i, j].axis(\"off\")  # Hide axes\n        if j == 0:\n            axes[i, j].set_ylabel(class_name, fontsize=12)\n\nplt.tight_layout()\nplt.subplots_adjust(top=0.9)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-11-09T15:31:41.939699Z","iopub.execute_input":"2024-11-09T15:31:41.940423Z","iopub.status.idle":"2024-11-09T15:31:45.295483Z","shell.execute_reply.started":"2024-11-09T15:31:41.940382Z","shell.execute_reply":"2024-11-09T15:31:45.294623Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**OASIS Dataset testing**","metadata":{}},{"cell_type":"code","source":"import os\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\n# Define the paths\ndataset_path = \"/kaggle/input/imagesoasis/Data\"  # Replace with your actual path\nclasses = [\"Mild Dementia\", \"Moderate Dementia\", \"Non Demented\", \"Very mild Dementia\"]\nsample_size = 5  # Number of images to display per class\n\n# Set up the plot grid\nfig, axes = plt.subplots(len(classes), sample_size, figsize=(15, 10))\nfig.suptitle(\"Sample Images from Each Class\", fontsize=16)\n\n# Loop through each class and display sample images\nfor i, class_name in enumerate(classes):\n    class_path = os.path.join(dataset_path, class_name)\n    images = os.listdir(class_path)[:sample_size]  # Get a few sample images\n    \n    for j, image_name in enumerate(images):\n        img_path = os.path.join(class_path, image_name)\n        img = Image.open(img_path).convert(\"RGB\")  # Convert to RGB if grayscale\n        axes[i, j].imshow(img)\n        axes[i, j].axis(\"off\")  # Hide axes\n        if j == 0:\n            axes[i, j].set_ylabel(class_name, fontsize=12)\n\nplt.tight_layout()\nplt.subplots_adjust(top=0.9)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-09T15:14:54.517758Z","iopub.execute_input":"2024-11-09T15:14:54.518697Z","iopub.status.idle":"2024-11-09T15:14:56.078510Z","shell.execute_reply.started":"2024-11-09T15:14:54.518657Z","shell.execute_reply":"2024-11-09T15:14:56.077452Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model8f=tf.keras.models.load_model(\"/kaggle/working/final_AD4_CNNs_5cnnL_8f.keras\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T10:33:57.474135Z","iopub.execute_input":"2024-12-14T10:33:57.474463Z","iopub.status.idle":"2024-12-14T10:33:58.043625Z","shell.execute_reply.started":"2024-12-14T10:33:57.474435Z","shell.execute_reply":"2024-12-14T10:33:58.042723Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_scores = model8f.evaluate(X_test, y_test)\nprint(\"Testing Accuracy: %.4f%%\" % (test_scores[1] * 100))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T21:46:13.411714Z","iopub.execute_input":"2025-08-23T21:46:13.412035Z","iopub.status.idle":"2025-08-23T21:46:14.885726Z","shell.execute_reply.started":"2025-08-23T21:46:13.412006Z","shell.execute_reply":"2025-08-23T21:46:14.884968Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tf.keras.utils.plot_model(model8f, to_file=\"model8f_plot_5cnnLD.png\", show_shapes=True, show_layer_names=True)","metadata":{"execution":{"iopub.status.busy":"2024-11-21T19:09:22.324539Z","iopub.execute_input":"2024-11-21T19:09:22.326180Z","iopub.status.idle":"2024-11-21T19:09:24.415626Z","shell.execute_reply.started":"2024-11-21T19:09:22.326107Z","shell.execute_reply":"2024-11-21T19:09:24.414245Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}